What Every Programmer Should Know About Floating-Point Arithmetic

A beginner programmer does not need to know the details of how float numbers
work in computer, but if you are the curious type, here we will explore it
little more.

# == Decimal Numbers (Float or sometimes "double")

# In most cases, Python will give you the result that you think it 'should' be
# with decimal numbers.
a = 11
print(a)

b = 2.5 
print(b + 2.5)
print(a + b)

# Decimal is also called Float. Some programming language also defines Double (Float)
print(1 / 3) # 0.333333... (repeat)

# NOTE: Today's Computer (any programming language, not just Python) can NOT represent 
# decimal numbers with EXACT value! It can only approximate, upt very large decimal 
# places... very close, but not exact.

# Example, python seems to print you a correct result of 0.3 here:
print(0.1 + 0.2)
# But if you ask Python to print 30 digits of decimal places in your answer,
# you will see that it is NOT all zeros!
print("{:.30f}".format(0.1 + 0.2))
# This prints 0.300000000000000044408920985006 -> 0.3000 000 000 000 000 44408920985006
# So the answer is only up with 15 decimal places accuracy. In many cases, it's
# enough for most problem solving.

For more details on this, there is a great website!
https://floating-point-gui.de/
